---  
type: TutorialClass  
title: 0.5-Dockerfiles  
description: We will go over Dockerfile syntax and instruction types. We will  
  end with a discussion on Multistage builds and other ways to make our custom  
  images more efficient and slender.  
share: true  
module: 0-Getting-Started  
created: Invalid date  
modified: Tuesday, 07-11-2023 16:06  
tags:  
  - shapecreations  
  - docker  
  - dockerfile  
  - image  
  - build  
media: ""  
status: complete  
---  
  
  
# 0.5-Dockerfiles  
  
![](https://img.shields.io/badge/-Docker-2496ED?logo=docker&logoColor=white&style=plastic)  
  
---  
  
## 🎯 Lesson Objectives  
  
> **By the end of this lesson, you should be able to:**  
> - Understand what a Dockerfile is and what they are used for.  
> - Define what cached layers are, how they build up, and what kind of information they track.  
> - Know Dockerfile syntax and how the instructions are ordered effects the performance of the container.  
> - List several instruction types, define them,, and describe their use cases.  
> - Discuss the differences between `ENV`, `ARG`, and `VOLUMES` and when you would use each.  
> - Understand how `CMD` and `ENTRYPOINT` differ from the other instructions.  
> - List ways to decrease image build time, increase container performance, and otherwise improve the security posturing of running services.  
> - Discuss the security implications and benefits for multi-stage builds.  
> - Understand how the `docker build` command interprets context and what it needs to successfully build a container.  
> - Know how to tag images.  
  
## ⛰ Overview  
  
> 🍎 Definition    
> A Dockerfile is a text file that contains all the commands and information necessary to build an image.  
  
Since we will need custom configurations for all of our images, we will be using [Dockerfiles](https://docs.docker.com/engine/reference/builder/#:~:text=Docker%20can%20build%20images%20automatically,can%20use%20in%20a%20Dockerfile%20.). Any Docker image found on the [Docker Hub](https://hub.docker.com/) uses a `dockerfile` to implement startup images. This can include installing built in programs, copying over external configuration files, setting a working directory, permissions, etc. We will be learning the syntax for such a file and configuring our images upfront in this way.  
  
> 🔦 Flashback    
> If you recall from [Module 1 - Lesson 0.3](./0.3-Docker-Primer.md#learning-the-lingo) images are made up of read-only layers that we then run a container from. As such, everything that goes in the `Dockerfile` will become embedded in these read-only layers.  
  
The result of these dockerfiles will be a custom configured image with all of the programs and configuration baked-in. We will also copy over the files from the project itself so certain containers have access to our live code but more on this later.  
  
Within a Dockerfile, there are several instruction types that can be used to do anything from run CLI programs, install programs, switch users, copy files from the host to the image, set the runtime command, and more! Before we take a look at our first Dockerfile, we will explore some best use practices and instruction types that you should become familiar with before commencing the project.  
  
The instruction types we will cover in this section and use throughout the project are as listed (in order of appearance):  
  
- [FROM](0.5-Dockerfiles.md#the-from-instruction)  
- [WORKDIR](0.5-Dockerfiles.md#the-workdir-instruction)  
- [ENV](0.5-Dockerfiles.md#env)  
- [ARG](0.5-Dockerfiles.md#arg)  
- [RUN](0.5-Dockerfiles.md#the-run-instruction)  
- [ADD](0.5-Dockerfiles.md#add)  
- [COPY](0.5-Dockerfiles.md#copy)  
- [VOLUME](0.5-Dockerfiles.md#volume)  
- [USER](0.5-Dockerfiles.md#the-user-instruction)  
- [EXPOSE](0.5-Dockerfiles.md#the-expose-instruction)  
- [CMD](0.5-Dockerfiles.md#cmd)  
- [ENTRYPOINT](0.5-Dockerfiles.md#entrypoint)  
  
> ✏ Note    
> We will only cover the basic usages of these commands, for a complete reference, check out the [Docker - Dockerfile Reference](https://docs.docker.com/engine/reference/builder/). Much of the information shared in this section comes directly from this resource anyways.  
  
## 🛑 General Rules  
  
Docker syntax is quite simple at its core. Comments are denoted with a `#` symbol and each command must be on its own line. While not required, all instructions are typically written using ALL CAPS.  
  
```Dockerfile  
# This is a comment  
FROM apache  
```  
  
Since we are writing the instructions to build a nicely packaged Docker image. Instructions are built in order and a few of the instructions themselves denote new layers including: .  
  
### 🧅 Cached Layers  
  
There are some considerations to be had when deciding when and where we put certain instructions. This is because when we build our images, a cache helps keep track of what has changed from the present build to the previous, then only building layers that have changed starting from the first change.  
  
In practice, this means putting instructions that copy code subject to change near the end and lengthy installations near the beginning so that we don’t have to rebuild installation layers each time a configuration file is changed.  
  
> 🔒 Security    
> Remember, each layer in an image can be inspected with `docker history`! Our layers should not contain any secrets or otherwise sensitive information. We will discuss how to get around this [soon](./0.6-Docker-Compose.md#the-secrets-attribute).  
  
### 📛 Naming the File  
  
Dockerfiles are usually named `dockerfile` (or some version of that). This helps, especially for VS Code to help auto suggestions. We will be using the `{service_name}.dockerfile` convention in our project as VS Code recognizes it.  
  
> 🔮 Crystal Ball    
 > We want VS Code to recognize these files because it will help us select valid base image variants and versions as well as help with syntax.  
  
### ⌨ The `FROM` Instruction  
  
Every Dockerfile needs a `FROM...` instruction at the beginning of the file. This is like the `docker pull` command on the CLI. In general, you can use any base image from the Docker Hub, but there are often variants and specific versions that can be specified.  
  
> ✏ Note    
> It is good practice to specify both of these things in our Dockerfiles as it will protect us from unforeseen differences between versions that can break our builds.  
  
Dockerfiles can be as simple as a `FROM` instruction but if this is all you need, you may as well build your image from the CLI. Nothing can precede a `FROM` instruction except comments or `ARG` instructions.  
  
### ⌨ The `WORKDIR` Instruction  
  
The `WORKDIR` instruction is used to set the working directory for use by the other Dockerfile instructions including: `RUN`, `CMD`, `ENTRYPOINT`, `COPY`, and `ADD`. This instruction greatly improves readability and maintains an active scope to keep things in the image straight. It may be used several times throughout the Dockerfile when creating complex file systems that will later be used by the containers run from the image.  
  
Here is a simple use case for the `WORKDIR` instruction using a simple `COPY` statement that copies a folder called `app/` in the current host directory to the working directory:  
  
```Dockerfile  
WORKDIR /path/to/working/directory  
  
COPY ./app .  
```  
  
> ✏ Note    
> Throughout our time with Docker, we will often use the `.` notation to refer to the current directory. This can be done to reduce relative paths as in `./app` which refers to a folder named `app/` within the current working directory of the host computer and `.` which refers to the current working directory denoted by the `WORKDIR` instruction.  
  
### 🔁 Variable Replacement: The `ENV` & `ARG` Instructions  
  
So I mentioned before that there are some exceptions to the layer per instruction rule. Two of those exceptions are the `ARG` and `ENV` instructions. These instructions are used to pass variables into our image build. We will discuss each individually as they should be used for two distinct purposes. Their shared purpose though is to prevent having to hardcode values that might otherwise be different for different image builds (e.g., development vs. production).  
  
#### ⌨ `ENV`  
  
The `ENV` instruction is used to replace values both during the image build and during container runtime. This means, `ENV` values can be accessed by the containers after an image is built using the Dockerfile.  
  
There are a number of ways we can set `ENV` variables. There is an order of precedence too that allows certain methods to override others. That order goes as follows (highest to lowest):[^1]  
  
1) Using the `-e` flag in a `docker compose -e` in the CLI.  
  
2) Substituted from your shell variables.  
  
3) Set using the `environment` attribute in the `docker-compose.yml` file.  
  
4) Use of the `--env-file` argument in the CLI  
  
5) Use of the `env_file` attribute in the Compose file  
  
6) Set using an `.env` file placed at base of your project directory  
  
7) Set in a container image in the `ENV` directive. Having any `ARG` or `ENV` setting in a `Dockerfile` evaluates only if there is no Docker Compose entry for `environment`, `env_file` or `run --env`.  
  
We will only consider a select few of these methods as most are not applicable within the scope of this project. When defining an `ENV` variable within the Dockerfile, the `ENV` key is often named using ALL CAPS and the syntax for `ENV` variables is as such:  
  
```Dockerfile  
ENV KEY=value  
  
RUN some_command ${KEY}  
```  
  
> 🔮 Crystal Ball    
> We will learn the syntax for defining `ENV` variables as a Docker Compose attribute in the next section.  
  
Once set in the Dockerfile, `ENV` values cannot be overridden from the command line at build time. They can however be changed after container runtime which can be useful if you wish to have a different value parsed in the container than what was used in the image itself. A common use for this is when you want to run different containers using the same image.  
  
You would very generally use `ENV` variables to pass credentials, certificates, secrets, and other sensitive information to the containers that require them.  
  
> 🔒 Security    
> We will not use `ENV` variables *directly* to send sensitive information to our containers. Instead, we will use a neat service provided by Docker called [Docker Secrets](https://docs.docker.com/engine/swarm/secrets/) (more on this later).  
  
#### ⌨ `ARG`  
  
The `ARG` instruction is used to pass variables at build time, which means they are only available within the scope of the image, not the container. Usually `ARG` variables are used when the container is not interested in the value or when you need to set a value dynamically at build time.  
  
There are far fewer ways to define an `ARG` variable than for `ENV` variables. Also note that given the same key name, an `ENV` variable will override the value set for the `ARG` variable.  
  
1) Defined at the CLI using `--build-arg` .  
  
2) Given a default value within a Dockerfile.  
  
3) Set using the `arg` attribute nested under the `build` attribute of a `docker-compose.yml` file service.  
  
> ⚠ Warning!    
> If an `ARG` variable is used in a Dockerfile but is not defined by one of these methods, a warning will be thrown at build time.  
  
The syntax for `ARG` instructions within a Dockerfile is identical to that of `ENV` instructions:  
  
```Dockerfile  
ARG KEY=value  
  
RUN some_command ${KEY}  
```  
  
> 🔮 Crystal Ball    
> It goes without saying that we will cover the Docker Compose syntax in the next section.  
  
> 🔒 Security    
> `ARG` instructions are *not* a good way to pass secrets, credentials, or other sensitive material to the image! Values passed this are visible to any user with the `docker history` command.  
  
> 🔦 Flashback    
> As mentioned in the `FROM` instruction heading, the `ARG` instruction is the only instruction that can precede it and the `ARG` itself must only be referenced in that `FROM` instruction, as for, the variant or version number. For example:  
>  
> ```Dockerfile  
> ARG VERSION=2.4.57  
> FROM httpd:${VERSION}  
> ```  
>  
> However, any `ARG` variables set above the `FROM` instruction must be re-declared below it to be made usable to the rest of the build.  
  
Something unique to `ARG` variables is that they can be set from the CLI using `--build-arg {ARGUMENT_VARIABLE}`. `ENV` variables cannot be dynamically changed in this way. This can be done as follows:  
  
```shell  
$ docker build --build-arg VARIABLE=value .  
```  
  
Common use cases for `ARG` variables are version numbers and tags for the base image and when setting a non-root user. We have also elected to use them to simplify host path names that are subject to change as our project directory evolves.  
  
> 🔮 Crystal Ball    
> In a rather unconventional way, we will be using a universal `.env` file to set our `ARG` variables using Docker Compose. This is not necessarily how our final project will handle `ARG` variables but it works and prevents the need to hardcode repetitive values into each Dockerfile.  
>  
> Security considerations on this are inconclusive at the time this Module has been written... We may implement an `build.sh` in the future to pass all `ARG` variables at the CLI to prevent their hardcoding into the container through the `.env` file.  
  
### ⌨ The `RUN` Instruction  
  
The `RUN` instruction is one of the most dynamic in the Dockerfile arsenal. Despite its power, it is relatively simple to explain. Use `RUN` to execute any shell program or command inside the image file space.  
  
The `RUN` instruction can take one of two forms:  
  
1) The *shell* form: `RUN <command> ` which should be used whenever executing a command via the `bin/sh -c` shell.  
  
2) The *exec* form: `RUN ["exectuable", "param1", "param2"]` which can be used to run a command from another shell by setting the `SHELL` instruction. We won’t use this form.  
  
Here is a simple example of using `RUN` to upgrade and update an ubuntu image:  
  
```Dockerfile  
FROM ubuntu:latest  
  
RUN apt-get update \  
	&& apt-get upgrade  
```  
  
> ✏ Note    
> Notice in the above example the `\` symbol is being used to separate multiple commands onto different lines. This is best practice as it helps to make code more readable. Consider also, alphabetizing commands listed in this manner to ease in program installations and such.  
  
> 🌎 The Big Picture    
> `RUN` is one of the commands that generates a new layer. Upon reaching a `RUN` instruction, a new read-only layer is added to the top of the current image.  
  
### 📤 The `ADD`, `COPY` & `VOLUME` Instructions  
  
There will be several files needed to be shared between our host computer and docker container; not least of which is the application folder itself! There are several options to do so but they are not necessarily interchangeable: (1) `ADD`, (2) `COPY`, and (3) `VOLUME`. Each comes with its own pros and cons, as well as special functionalities that make them preferable to the others for certain types of files.[^2]  
  
> 🔒 Security    
> Pay attention to best use cases for each of these *file sharing* instructions, often our biggest consideration when deciding between the three is whether or not we want to obfuscate or persist data (even when a container is stopped!).  
  
#### ⌨ `ADD`  
  
The `ADD` instruction can be used to add new files, directories, or remote file URLs to a destination within the image file system. Though it was the standard in the early days of Docker, it has since been replaced with the `COPY` instruction.  
  
> 🔒 Security    
> This instruction is outdated and unpredictable, Docker even advises against using it in its [Best Practices](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#:~:text=COPY%20only%20supports%20the%20basic,rootfs.tar.xz%20%2F%20.) documentation. It is also incapable of handling remote files using secure protocols. These types of adds are best left to `RUN wget` or `RUN curl` instructions.  
  
#### ⌨ `COPY`  
  
The programmers at Docker designed the `COPY` instruction to replace the local file copying functionality of the `ADD` instruction. It is more reliable and simplistic but it does its job. It is used to make local files available within the image file system, i.e., configuration files, code, etc.  
  
The `COPY` instruction currently takes two forms both with optional commands to set permissions. This greatly improves functionality when using the `USER` instruction and granting this new user permissions on added files.  
  
- `COPY [--chown=USER:GROUP] [--chmod=permissions] <source> <destination>`  
- `COPY [--chown=USER:GROUP] [--chmod=permissions] ["source",... "destination"]'  
  
#### ⌨ `VOLUME`  
  
Before we get to the `VOLUME` instruction, Volumes deserve a bit more of an explanation as they are a major concept in Docker at large. Volumes allow you to share files between the host and the image file system and *persist* even if you stop the container!  
  
> ⚠ Warning!    
> Data does not naturally persist in a container. It only exists so long as a container is running; once a container is stopped, the data is lost. If you want data within a container to persist, you must use either volumes or a bind mount. Bind mounts won’t be discussed in this tutorial.  
  
There are two types of volumes, each with their own use cases. The main thing to remember is that with a volume, there is a link between some folder on the host computer and a folder within the container. When declaring a volume, the connection is initialized within the image build step but does not become active until container runtime to maintain portability.  
  
- *Anonymous* volumes store data from the container somewhere in the host filesystem. Where is not important and is unnecessary if you just wish for data to persist between container stops. Once you remove the container, it is lost but still exists somewhere in the file system. You can use a `-rm` flag in the `docker run` command when at the CLI to automatically remove these volumes or you can manually remove them using the `docker volume prune` command.  
- *Named* volumes are different in that the location of the data on the host file system is known and defined by the user. This is useful if you want to share changes to files back and forth between the host and container. Data shared in this way updates live; as changes are made in the local folder or the container folder, they are reflected in the other. This is how we will connect our source code to the container as we wouldn’t want to have to constantly have to rebuild our image every time we make an update. These types of volumes are not removed automatically as it would be dangerous if Docker was able to delete files from your computer.  
  
When declaring a volume in an image you can do it a number of ways:  
  
| Volume Type           | Anonymous                           | Named                                        |  
| --------------------- | ----------------------------------- | -------------------------------------------- |  
| From the CLI          | `docker run -v <destination> IMAGE` | `docker run -v <source>:<destination> IMAGE` |  
| Within the Dockerfile | `VOLUME ["/data"]`                  | `VOLUME ["/host/data":"/container/data"]`    |  
| Using Docker Compose  | Use the `volumes` attribute.          | Use the `volumes` attribute.                                             |  
  
> 🔮 Crystal Ball    
> We will opt for the Docker Compose option as we wish to have separate image builds for development and production. This concept as well as other project design principles will be discussed at length in the next Module.  
  
### ⌨ The `USER` Instruction  
  
By default, Docker containers are run (and images are built) as root user. It isn’t obvious why at first, as this sounds like a major security concern. But especially in the build phase, the image user needs to have permission to install commands, make directories, etc. So it makes sense to use root during these steps. However, this should not be the case in our running container.  
  
Thankfully, we can change the user in the latter parts of our build that continues when running the container. We do this using the `USER` instruction, which has two forms:  
  
- `USER <user>[:<group>]`  
- `USER <uid>[:<gid>]`  
  
Before we can assign a user we must first create the new user (and group) with `RUN addgroup...` and `RUN adduser...` instructions. We must also grant permissions to the files, folders, commands, etc. that we wish the user to have access too. We do this using `RUN chown <user>:<group> /path` instructions. The order in which we issue Dockerfile instructions is very dependent on these processes.  
  
### ⌨ The `EXPOSE` Instruction  
  
Mainly a formality, the `EXPOSE` instruction documents which port/s are exposed in the eventual container. Adding this to your Dockerfile is not necessary but it is good practice. It has simple syntax: `EXPOSE <port>` and you can list multiple ports.  
  
### 🚪 The `CMD` & `ENTRYPOINT` Instructions  
  
The `CMD` & `ENTRYPOINT` instructions are oddballs when compared to the other Dockerfile instructions. First and foremost, they are not a build time instructions like all the others; they are runtime commands that define the default behavior of the `docker run` command.  
  
#### ⌨ `CMD`  
  
`CMD` is used to set a default run command that will execute once a container is started from that particular image (or omit the default run command). A `CMD` instruction can also be overridden during the `docker run` command and will be replaced by whatever is entered at the CLI. `CMD` should be used if your container may be run in interactive mode or will otherwise be run in varying ways.  
  
It can take three forms:  
  
- The preferred form is the *exec* form: `CMD ["executable", "param1", "param2"]`  
- As a default for the `ENTRYPOINT` instruction: `CMD ["param1", "param2"]`  
- The *shell* form in which the `SHELL` instruction should be used to define the desired shell: `CMD executable param1 param2`  
  
There can only be one `CMD` instruction in a given Dockerfile (any duplicates will result only in the last being valid). And it is convention that this instruction be declared at the end of the Dockerfile.  
  
#### ⌨ `ENTRYPOINT`  
  
Much like the `CMD` instruction, the `ENTRYPOINT` instruction also defines the default command that will be executed once a container is run. By contrast though, the `ENTRYPOINT` instruction cannot be overridden by commands or parameters passed in the `docker run` command. This is why, when possible, `ENTRYPOINT` should be used over `CMD`. Always use `ENTRYPOINT` when you need your container to be run as an executable!  
  
`ENTRYPOINT` can be invoked two ways:  
  
- The preferred form is the *exec* form: `ENTRYPOINT ["executable", "param1", "param2"]`  
- The *shell* form in which the `SHELL` instruction should be used to define the desired shell: `ENTRYPOINT executable param1 param2`  
  
> ✏ Note    
> If need be, `ENTRYPOINT` can be replaced at the CLI using the `--entrypoint` flag when starting up a container.  
  
#### 🍻 Using `CMD` & `ENTRYPOINT` Together  
  
It was alluded to earlier in this section, but there are some use cases where it is beneficial to use both `CMD` and `ENTRYPOINT` together. We might choose to do so if we have a container that we wish to only be used for a certain command but that might have different or additional parameters passed at run time.  
  
Here is the Dockerfile syntax and the proceeding Docker command for a simple container named `greeting-container` that prints `Hello <name>`. The default command is given by `ENTRYPOINT`, default parameter is given by `CMD` instruction, and if desired, a different parameter may be passed through the `docker run` command to replace that default given by `CMD`:  
  
```Dockerfile  
FROM ubuntu  
ENTRYPOINT ["echo", "Hello"]  
CMD ["Ms. Nyki"]  
```  
  
If we run Version 1 of the command, we get the output `Hello Ms. Nyki`. Version 2 will print out the alternative message of `Hello Ms. Anderson`.  
  
```shell  
# Version 1  
$ docker run greeting-container  
  
# Version 2  
$ docker run greeting-container "Ms. Anderson"  
```  
  
> ✏ Note    
> When using the two instructions together, be sure to use the `exec` form of both.  
  
## 🧠 Advanced Topics  
  
Two of the biggest concerns when designing Dockerfiles are build time and image size.  
  
### 👯 Multi-Stage Builds  
  
## 🏗 The `docker build` Command  
  
Now that you could write your own Dockerfile, all that’s left is to build an image with all that hard work. The general syntax for `docker build` is below.  
  
```shell  
$ docker build [OPTIONS] PATH | URL | -  
```  
  
At its simplest, you can build a full image from a Dockerfile as follows, where `.` refers to the current working directory. Be careful with your context because it must contain any and all of the files or data needed by the instructions themselves. You cannot just use `../` to leave the context because the Dockerfile will not have access. We discuss the `context` option a little more in the following [lesson](./0.6-Docker-Compose.md#context). Despite the expansiveness of the `docker build` command, all it needs to build successfully is a Dockerfile and a context.  
  
```shell  
$ docker build .  
```  
  
The above command only works because the Dockerfile is in the same directory and is named `dockerfile`. If either of those is not the case you can use the `-f` or `--file` flag with the path to the Dockerfile relative to the current directory as follows:  
  
```shell  
$ docker build -f /path/to/dockerfile .  
```  
  
### 🧾 Tagging Images  
  
Just like how we can use the `docker run -n CONTAINER_NAME` command to avoid the confusing randomly generated name that Docker gives to containers, we can similarly name our images rather than having to run `docker image ls` for the `IMAGE_ID`. Do this using the `-t` or `--tag` flag and passing a custom name and version. Omitting the version will revert to `latest`.  
  
```shell  
$ docker build -t TAG:VERSION .  
```  
  
### 🔔 Read-only Reminder  
  
> 🔒 Security    
> Keep in mind, once an image is built, the instructions are baked into its read-only layers. Even if you stop and restart a container, the image’s `history` remains the same until you `prune` it.  
  
Accidentally building sensitive variables, files, or secrets is okay during development, as you can easily just remove an image and build it again and again until you get it right. But this process will get tedious quickly! It’s best to go back through this lesson if you are uncertain about any topics and follow the `See Also` links I’ve provided or visit the references at the bottom of the page. Start with the `run`  
  
> 🪟 See Also    
> To learn more about the `docker build` command see the [Docker Documentation](https://www.udemy.com/share/103Ia03@NIeuWLCBpXz9Asqz04rkP-_CNSQIKXErlgRJiOPMlNKtC0p-elHO_4KXZAlK3wo=/) site. [^3]  
  
## 🏃‍♀ The `docker run` Command  
  
With a tagged image you are free to use it to execute the `docker run` command just as you did with the `IMAGE_ID` though there is so much more to the command than that. `docker run` has some of the most extensive functionality of any of the Docker commands. It follows simple mechanics but it can still be confusing understanding where certain flags can be placed and where others cant’t.  
  
```shell  
$ docker run [OPTIONS] IMAGE [COMMAND] [ARG...]  
```  
  
### 🎏 Flags, Flags, Flags  
  
Three are dozens of options, for the `docker run` command because it has to be able to control the varied and complex behavior of containers. and their interactions with other containers. We will cover a small few flags that we will use in special cases because we won’t end up using the rest (that’s what Docker Compose is for).  
  
> 🔮 Crystal Ball    
> Furthermore, in the [next lesson](./0.6-Docker-Compose.md#) we will learn how the tool Docker Compose can help us avoid using flags at all, even when running more than one container at a time. Through that process, I will show you some ugly `docker run` experiences and briefly explain what’s going on before showing you how to leave it all behind.  
  
To make matters a little more complicated, almost every flag can take a short or long form: generally flags can either use a single hyphen when in long form and two when using the shorthand (for example, to define a volume you can use `--volume` or simply, `-v` . For example:  
  
```shell  
$ docker run -v data:/path/to/data -v ./some/path:/some/other/path TAG:VERSION  
```  
  
Here’s a non-exhaustive list of some common flags that correspond to instructions and concepts you are already familiar with:  
  
#### ✂ Detached Mode  
  
Running a container in detached mode simply frees up the terminal to issue further commands. It is denoted using `-d` or `--detached` and forces the container to be run in the background. If you don’t use detached mode you will have to open another terminal as long as that container is still running.  
  
```shell  
$ docker run -d TAG:VERSION  
```  
  
### 🚫 No More CLI  
  
We won’t be covering much more in the way of the `docker run` command. Knowing how to run containers from the CLI is very useful for small, simple images with just a couple instructions to run. However, things can quickly get out of hand when you mounting volumes, copying files, and passing environment/arguments inline.  
  
## 🎁 Wrapping Up  
  
We will be designing our Dockerfiles to handle everything our images need to run securely and efficiently, so I will spare you flag-hell. The commands above should serve you just fine in most cases.  
  
> 🪟 See Also    
> I learned everything I know about Dockerfiles from [Docker & Kubernetes: The Practical Guide [2023 Edition] | Udemy](https://www.udemy.com/share/103Ia03@NIeuWLCBpXz9Asqz04rkP-_CNSQIKXErlgRJiOPMlNKtC0p-elHO_4KXZAlK3wo=/). [^4]  
  
---  
  
## 📖 References  
  
[^1]: Docker. (2023, July 8). *Environment variables precedence*. Docker Documentation. <https://docs.docker.com/compose/environment-variables/envvars-precedence/>  
  
[^2]: Simic, S. (2019, December 16). *Docker ADD vs COPY: What is the Difference and Which One to Use?* Knowledge Base by PhoenixNAP. <https://phoenixnap.com/kb/docker-add-vs-copy>Docker. (2023b, July 8). *Share Compose configurations between files and projects*. Docker Documentation. <https://docs.docker.com/compose/extends/#adding-and-overriding-configuration>  
  
[^3]: Docker. (2019, November 15). *docker build*. Docker Documentation. <https://docs.docker.com/engine/reference/commandline/build/>  
  
[^4]: Scwarzmüller, M. (2023). Docker & Kubernetes: The Practical Guide [MOOC]. Section 5: Building Multi-Container Applications with Docker. Udemy. <https://www.udemy.com/share/103Ia03@NIeuWLCBpXz9Asqz04rkP-_CNSQIKXErlgRJiOPMlNKtC0p-elHO_4KXZAlK3wo=/>   
