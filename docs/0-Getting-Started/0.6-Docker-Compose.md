---  
type: TutorialClass  
title: 0.6-Docker-Compose  
description: This section will attempt to explain Docker Compose and the  
  attributes that allow us to build multiple dynamic images with one command, as  
  well as some advanced topics guided by project design principles.  
share: true  
module: 0-Getting-Started  
created: Saturday, July 8th 2023, 4:50:15 pm  
modified: Monday, July 10th 2023, 8:01:47 am  
tags:  
  - shapecreations  
  - docker  
  - docker-compose  
  - attributes  
  - yaml  
media: ""  
status: complete  
---  
  
  
# 0.6-Docker-Compose  
  
---  
  
## Overview  
  
[Docker Compose](https://docs.docker.com/compose/) is a wonderful tool that is used to build and run multi-container Docker projects in one step. It provides a more readable and portable experience when building our images and designing our container runtime behaviors. Anything that can be accomplished in the Docker CLI can be done in a Docker Compose configuration file. Docker Compose is now an extension of Docker itself and has its own syntax.  
  
You can get help for any `docker compose` commands using the `--help` flag just as with any other Docker command.  
  
```shell  
$ docker compose --help  
```  
  
> 🔮 Crystal Ball    
> While Docker Compose relieves us of the need to use Docker fully in the command line, I will attempt to show the equivalent commands to give us some perspective on how helpful the tool really is.    
  
## The `docker-compose.yml` File  
  
The Docker Compose configuration file is written in yaml format which has super easy to learn, element-/attribute-based syntax. This file is generally named `compose.yml` or `docker-compose.yml` but the `docker compose...` command can accept any yaml file using the `-f` flag.  
  
Here is an excerpt from a typical `docker-compose.yml`.  
  
```yml  
version: '3.8'  
services:  
	foo:  
		image: httpd  
	bar:  
		build:  
			context: .  
			dockerfile: Dockerfiles/dockerfile  
```  
  
## Elements & Attributes  
  
There are many possible elements/attributes but not every service will need the same ones, the build is as customizable as possible. We will go through the most important ones, especially those we will make use of through this project.  
  
> 🪟 See Also    
> For a complete list of all elements and attributes, visit the [Docker Compose Documentation](https://docs.docker.com/compose/compose-file/)  
  
Top-level elements are not indented and define high-level aspects of the project. They should be justified to the far left of the yaml file. There can be space between the start of each top-level element but it is not necessary, the yaml parser is mostly concerned with white space and tabbed indents. Definitions and attributes are nested using a tabbed indent, following a cascading effect.  
  
### Version (Top-Level)  
  
While not required it is good practice to begin your Docker Compose file with the version with which you want it to be parsed. At the time of this tutorial, Docker Compose is on version 3.8. There are no nested attributes for the `version` element.  
  
```yml  
version: 3.8  
```  
  
### Services (Top-Level)  
  
Every Docker Compose file must include the `services` element. We have used the word **services** throughout this project to describe the various containers we require. This is where we get the term from.  
  
> 🍎 Definition    
> **Services**: A service is an abstract concept. Think of services like resources that can be scaled and configured to your exact specifications and backed by a container. They are our web servers, interpreters, and database management programs: i.e., apache, php, mariadb, etc.  
  
As the root element, each service has a set of definitions that dictate how a container will run and an optional build section that defines the image build. This is where we define the runtime constraints and requirements with which our containers will be designed. Nested under services is a unique identifier that will only be used within the file itself. The majority of our attributes will be nested under this unique identifier.  
  
> ✏ Note    
> The `container_name` attribute is used to define a container name. All images are named using the convention: `COMPOSE_PROJECT_NAME-<container_name>` where `COMPOSE_PROJECT_NAME` is given by the root folder name of the project.  
  
```yml  
services:  
	foo:  
```  
  
Here’s a list of the `servcies` attributes we will cover (in order of appearance):  
  
- [build](0.6-Docker-Compose.md#the-build-subsection)  
	- [context](0.6-Docker-Compose.md#context)  
	- [dockerfile](0.6-Docker-Compose.md#dockerfile)  
	- [args](0.6-Docker-Compose.md#args)  
- [image](0.6-Docker-Compose.md#the-image-attribute)  
- [container_name](0.6-Docker-Compose.md#the-containername-attribute)  
- [restart](0.6-Docker-Compose.md#the-restart-attribute)  
- [ports](0.6-Docker-Compose.md#the-ports-attribute)  
- [env_file](0.6-Docker-Compose.md#the-envfile-attribute)  
- [environment](0.6-Docker-Compose.md#the-environment-attribute)  
- [networks](0.6-Docker-Compose.md#the-networks-attribute)  
- [secrets](0.6-Docker-Compose.md#the-secrets-attribute)  
- [links](0.6-Docker-Compose.md#the-links-attribute)  
- [volumes](0.6-Docker-Compose.md#the-volumes-attribute)  
  
#### The `build` Subsection  
  
The `build` subsection is a special case and is completely optional and it defines build time configuration or images. All of the other sections we will cover (true attributes) deal with runtime configuration or containers. `build` is only necessary when using a custom Dockerfile, such as the ones we will be using.  
  
> 🔮 Crystal Ball    
> If there is no `build` section, the `image` attribute must be used in its place. The `image` attribute is the easiest way to build an image, it is like using the `docker pull IMAGE` command.  
  
Unlike regular attributes, the `build` subsection has its own attributes nested under it. We will talk about the three we will use in our project: (1) `context`, (2) `dockerfile`, and (3) `args`.  
  
##### `context`  
  
The `context` attribute defines the path for `dockerfile` of that service or the URL to a github repository. It defaults to `.` (the directory of the `docker-compose.yml`).  
  
> ⚠ Warning!    
> To use this attribute, without needing the `dockerfile` attribute as well, your Dockerfile must be named `dockerfile` (no extension).  
  
```yml  
services:  
	foo:  
		build:  
			context: `.`  
```  
  
> ✏ Note    
> In my experience, setting this value to `.` or not including it at all tends to be the best option, especially if your project files are kept in separate folders based on file type rather than by image/container. The file system for this project keeps Dockerfiles in their own folder and configuration files for each service in their own folders so the Dockerfile would have difficulty locating these files if we didn’t set the context to the main project directory.  
  
##### `dockerfile`  
  
The `dockerfile` attribute allows us to set a different name for the Dockerfile of the image being built. We will need this as we have opted to use this naming convention: `<service>.dockerfile`.  
  
```yml  
services:  
	foo:  
		build:  
			dockerfile: ./DOCKERFILE  
```  
  
###### `args`  
  
The `args` attribute is completely optional and is elected based on personal preference. It is used when you wish to define `ARG` variables (as in the Dockerfile) in your Docker Compose file instead. You would still need to declare the `ARG` variable name inside the Dockerfile but the actual value can be set in the Docker Compose file.  
  
So with this `ARG` instruction in the Dockerfile:  
  
```Dockerfile  
ARG SOME_ARG  
  
USER ${SOME_ARG}  
```  
  
You can define the value of the variable like this in the Docker Compose file.  
  
```yml  
build:  
	foo:  
		args:   
			- SOME_ARG=some_value  
```  
  
#### The `image` Attribute  
  
The `image` attribute denotes which base image to run the container from. This attribute takes the place of the entire `build` section. The `image` attribute takes an image name from Docker Hub and optionally, a tag and/or version, like our Dockerfile `FROM` instruction.  
  
```yml  
services:  
	foo:  
		image: httpd:2.4.57-alpine3.18  
```  
  
> ⚠ Warning!    
> If not using the `build` section, you must include the `image` attribute. Without an `image` or `build` section, Docker Compose will not work.  
  
#### The `container_name` Attribute  
  
The `container_name` attribute is a string name for the container. If you do not specify this, a default name will be generated. The regex rules for this string are: ‘\[a-zA-Z0-9\]\[a-zA-Z0-9_.-\]+’  
  
```yml  
services:  
	foo:  
		container_name: CONTAINER_NAME  
```  
  
> ✏ Note    
> Specifying a `container_name` will automatically give the image the name `COMPOSE_PROJECT_NAME-CONTAINER_NAME`.  
  
#### The `restart` Attribute  
  
The `restart` attribute determines the policy for the container if its run is terminated. There are four options:  
  
- `no` : This is the default policy and the container will not restart under any circumstances.  
- `always` : This policy will restart the container until it is removed.  
- `on-failure` : This policy will restart the container if an error is thrown.  
- `unless-stopped` : This policy will continue to restart the container until it is stopped or removed.  
  
```yml  
services:  
	foo:  
		restart: "no"  
	    restart: always  
	    restart: on-failure  
	    restart: unless-stopped  
```  
  
#### The `ports` Attribute  
  
The `ports` attribute exposes and maps container ports. Unlike the `EXPOSE` instruction used in Dockerfiles, this is not for documentation. The ports enumerated below will be equivalent to the CLI statement `docker run -p HOST_PORT:CONTAINER_PORT`  
  
```yml  
services:  
	foo:  
		ports:  
			- HOST_PORT:CONTAINER_PORT  
			- 8080:80  
```  
  
#### The `env_file` Attribute  
  
The `env_file` attribute takes a path (relative to the Docker Compose file) to a file containing environment variables for the container. You may specify more than one environment file. Though it is not mandatory, the naming convention for this file is simply `.env` though you can name this file whatever you like.  
  
An environment file simply uses the following syntax to define variables:  
  
```env  
VARIABLE1=value1  
VARIABLE2=value2  
```  
  
To attach an `.env` file to a Docker service, declare under the `env_file` attribute. To then use these variables in your Dockerfile, use the `${VARIABLE1}` or `$VARIABLE1` syntax.  
  
```yml  
services:  
	foo:  
		env_file:   
			- ./ENV_FILE_PATH  
```  
  
> 🔦 Flash Back    
> The order of precedence for environment variables described in the [previous section](./0.5-Dockerfiles.md#env) states that any environment variables defined in an `environments` attribute will overrule those in a file found at the path in the `env_file` attribute.  
  
#### The `environment` Attribute  
  
The `environment` attribute defines environment variables in a container, much in the same way that the `env_file` does. However, these values do supersede any found in an environment file. The syntax for this attribute can take one of two forms:  
  
1. *Mapping* syntax:  
  
```yml  
services:  
	foo:  
		environment:  
			ENV_VAR1: env_value1  
			ENV_VAR2: env_value2  
```  
  
1. *Array* syntax:  
  
```yml  
services:  
	foo:  
		environment:  
			- ENV_VAR1=env_value1  
			- ENV_VAR2=env_value2  
```  
  
#### The `networks` Attribute  
  
The `networks` attribute defines the networks to which services are attached. It references named networks declared in the top-level [networks](0.6-Docker-Compose.md#networks-top-level) element. One of the perks of Docker Compose container orchestration is that it automatically creates a network shared between all of the containers. We will use this built in network for now but it is worth noting how to define your own networks.  
  
There are a lot of attribute options and flags that can be used to design a network definition but we won’t get into them since we have opted to use the built-in Docker Compose network for now.  
  
```yml  
services:  
  foo:  
    networks:  
      - network1  
      - network2  
  
networks:  
	network1:  
	network2:  
```  
  
#### The `secrets` Attribute  
  
When it comes to managing secrets and other sensitive data like certificates and credentials, Docker Swarm offers a service called [secrets](https://docs.docker.com/engine/swarm/secrets/). Secrets are stored as encrypted files in the container file system at the path `/run/secrets/<secret_name>`. They are released to containers on a per-service basis and are encrypted during transit. Once a container is stopped, the secret is unmounted from the container.  
  
In order to use secrets you must initialize Docker Swarm with the command `docker swarm init`. You can create a secret several different ways:  
  
- From the CLI:  
	- Create from string: `printf "my super secret password"|docker secret create my_secret`  
	- Create from file: `docker secret create SECRET_NAME ./secret.txt`  
- Within the Docker Compose file:  
	- Create a new secret by using the `file` attribute to set the relative path to the secret file.  
	- Reference a secret that already exists: by setting the `external` attribute to `true`.  
  
```yml  
services:  
	foo:  
		secrets:  
			- certificate  
			- gpg_key  
secrets:  
	server_certificate  
		file: ./server.cert  
	gpg_key:  
		external: true  
```  
  
Some images, including the MariaDB base image we will be using, have their own built-in environment variables for secrets. The syntax for such a container will be as follows:  
  
```yml  
services:  
	mariadb:  
		environment:  
			- MARIADB_USER_FILE=/run/secrets/db-user  
			- MARIADB_PASSWORD_FILE=/run/secrets/db-password  
		secrets:  
			- db-user  
			- db-password  
secrets:  
	db-user:  
		file: ./db-user.txt  
	db-password:  
		external: true  
```  
  
#### The `links` Attribute  
  
The `links` attribute does two things: (1) it allows communication between different services across a network and (2) it denotes dependency thus determining the order of service startup. In the case below, the services `foo` and `bar` will be able to communicate over a shared network and `bar` will start before `foo`.  
  
```yml  
services:  
	foo:  
		links:  
			- bar  
	bar:  
```  
  
#### The `volumes` Attribute  
  
The `volumes` attribute defines a bind mount or named volume between a service and the host machine. We will not cover bind mounts at this time (maybe in a future edit) but when it comes to named volumes, there are certain use cases that will change where we declare them.  
  
If a volume is being used by a singular service, it can be declared one of two ways but is not required to be referenced in the top level `volumes` element. There are a lot of optional attributes and flags that can be used, for brevity, we’ve only included those that we either use currently or may use in future edits.  
  
- Long-syntax:  
	- `type`: The mount type. There are more types than this but these are the most popular.:  
		- `volume`  
		- `bind`  
	- `source`: The source of the mount, a path on the host for the bind mount, or the name of volume listed in the top-level volumes key.  
	- `target`: The path in the container where the volume is mounted.  
	- `read_only`: A flag to set the container to read only.  
	- `volume`: Configure additional volume options.  
		- `no_copy`: A flag to disable copying of data into the container when a volume is created.  
  
```yml  
services:  
	foo:  
		volumes:   
			-   type: volume  
			    source: db-data  
		        target: /data  
```  
  
- Short-syntax  
	- `volume`: A volume name.  
	- `container_path`: The path in the container where the volume is mounted.  
	- `access_mode`: A comma separated list of options (optional).  
		- `rw`: Read-write access (default).  
		- `ro`: Read-only access.  
  
```yml  
services:  
	foo:  
		volumes:  
			- VOLUME1:CONTAINER_PATH1:ACCESS_MODE  
			- VOLUME2:CONTAINER_PATH2  
```  
  
> 🔒 Security    
> Volumes are fairly secure innately, however they do lead back to the host machine which increases the attack surface of the project. They are also dependent on the host machine in which the container is being run on. For these purposes, we will exclude volumes from our production build but will still need them in development. To do this, we will make use of multiple Docker Compose files, a master `docker-compose.yml` and a `docker-compose-dev.yml` which will only define our volumes.  
  
> 🪟 See Also    
> Reference the [Using Multiple Docker Compose Files](0.6-Docker-Compose.md#using-multiple-docker-compose-files) heading later in this section for information on using multiple Docker Compose files.  
  
If a volume is to be shared between multiple containers, we must also declare named volumes in the top-level [Volumes](0.6-Docker-Compose.md#volumes-top-level) element. In these cases, the syntax would look like this:  
  
```yml  
services:  
  foo:  
    volumes:  
      - data:/etc/data  
  
  bar:  
    volumes:  
      - data:/var/lib/backup/data  
  
volumes:  
  data:  
```  
  
### Networks (Top-Level)  
  
> 🪟 See Also    
>The `networks` element works in conjunction with attribute within the `services` element. See the [network](0.6-Docker-Compose.md#the-networks-attribute) attribute section for syntax and usage.  
  
### Volumes (Top-Level)  
  
> 🪟 See Also    
> The top-level `volumes` element need only be used if a volume is being shared among multiple containers. Look to the [volumes](0.6-Docker-Compose.md#the-volumes-attribute) attribute section for syntax in this special case. There are a few optional attributes that aid in the specifications for how a volume will function but they are all beyond the scope of this tutorial.  
  
### Secrets (Top-Level)  
  
> 🪟 See Also    
> The top-level `secrets` element *must* be used in all cases when handling secrets. It can either define a new secret or reference a secret that already exists (such as those created in the CLI). Review the [secrets](0.6-Docker-Compose.md#the-secrets-attribute) attribute for syntax.  
  
## Putting it All Together  
  
Docker Compose is meant to allow you to do anything that can be accomplished at the CLI through a readable and portable format. Gone are the days when you need to define ports, volumes, environment variables, etc. with a never ending block of Docker flags at the CLI.  
  
> 🔦 Flashback    
> In our [Hello World](./0.4-Docker-CLI.md#testing-our-installation-with-hello-world) example, we simply pulled the base image from using `docker pull` and then used `docker run IMAGE` to start the container. In practice, Docker services will rarely be that simplistic. Most containers will require a little more elbow grease but the same principles can be applied.  
  
Prior to Docker Compose, running a moderately dynamic apache container would require multiple steps and a seriously long `docker run` command. I will show you how to start a container the traditional way and then show you how to use what we learned about Docker Compose to do the same thing in a single step.  
  
### The Hard Way  
  
As you have seen in this section, there are hundreds of ways to customize your Docker configuration and at least as many ways to do it wrong. Imagine for a moment, that if you wanted to run a simple three-service project you would need to complete the following steps. This part of the tutorial is borrowed from the same [Udemy](https://www.udemy.com/share/103Ia03@NIeuWLCBpXz9Asqz04rkP-_CNSQIKXErlgRJiOPMlNKtC0p-elHO_4KXZAlK3wo=/) course I have been referencing (Scwarzmüller, 2023). It will build a Node/React website complete with a MongoDB database,  
  
(1) Create a network.  
  
```shell  
$ docker network create goals-net  
```  
  
> ❓ Questions?    
> This is pretty self-explanatory but it is important to note that when starting a multi-container project, you need to create a shared network and reference it in each container’s `docker run` command.  
  
(2) Run a MongoDB Container using the standard base image `mongo`.  
  
```shell  
$ docker run --name mongodb \  
	-e MONGO_INITDB_ROOT_USERNAME=max \  
	-e MONGO_INITDB_ROOT_PASSWORD=secret \  
	-v data:/data/db \  
	--rm \  
	-d \  
	--network goals-net \  
	mongo  
```  
  
> ❓ Questions?    
> There are a bunch of flags being thrown around, so let’s connect each one to a concept we learned in Docker Compose.  
> - `--name` flag: Sets a container name rather than let Docker auto-generate one.  
> - `--environment` or `-e` flag: Sets an environment variable and makes it available to the container.  
> - `--volume` or `-v`: Creates a bind mount or volume (can be named or anonymous). Notice how you must use the absolute path for the source path.  
> - `--rm`: Automatically removes the container when it is stopped.  
> - `-d`: Runs the container in the background. It is short for detached mode. Without this you will not be able to issue another command to the terminal until the container is stopped.  
> - `--network`: Defines the network that the container will use. Must already exist.  
  
(3) Build Node API image from a custom Dockerfile located within the same directory.  
  
```shell  
$ docker build -t goals-node .  
```  
  
> ❓ Questions?    
> Unlike the first container, this one is being built from a Dockerfile. This adds an extra step.  
> - `-t` or `--tag`: Defines a custom name for the image rather than having to use the IMAGE_ID.  
  
(4) Run the Node API Container.  
  
```shell  
$ docker run --name goals-backend \  
	-e MONGODB_USERNAME=max \  
	-e MONGODB_PASSWORD=secret \  
	-v logs:/app/logs \  
	-v /Users/agbrat/development/docker-project/backend:/app \  
	-v /app/node_modules \  
	--rm \  
	-d \  
	--network goals-net \  
	-p 80:80 \  
	goals-node  
```  
  
> ❓ Questions?    
> To add more complications, this Node server requires a port to be exposed.  
> - `-p` or `--port`: Maps a host port to the exposed container port.  
  
(5) Build React. SPA image from custom Dockerfile located in the same directory.  
  
```shell  
$ docker build -t goals-react .  
```  
  
(6) Run React SPA container.  
  
```shell  
$ docker run --name goals-frontend \  
	-v /Users/agbrat/development/docker-project/backend:/app/src \  
	--rm \  
	-d \  
	-p 3000:3000 \  
	-it \  
	goals-react  
```  
  
> ❓ Questions?    
> This container is going to be used in interactive mode.    
> `-it`: Short for interactive. Allows you to enter commands within the container at the terminal once it is started.  
  
(7) Stop all containers. And remove images.  
  
```shell  
$ docker stop mongodb goals-backend goals-frontend  
$ docker image prune -a  
```  
  
That would be your normal workflow as you trouble shoot and configure your project. After seven steps at the CLI, you would be quite dismayed if you found out that your image wasn’t configured correctly and that you need to rebuild.  
  
### The Easy Way  
  
It should already be clear why Docker Compose is absolutely necessary as a project becomes more complex but we will drive this idea home by throwing up the same three containers. This time, we will be using a `docker-compose.yml`. Assume the same Dockerfiles are used and in the same directory. Check out this Docker Compose file and mentally verify that it is indeed the same as the previous commands.  
  
```yml  
version: '3.8'  
  
services:  
	mongodb:  
		image: 'mongo'  
	   container_name: mongodb  
		volumes:  
			- data:/data/db  
	   environments:  
	       MONGO_INITDB_ROOT_USERNAME: AgBRAT  
	       MONGO_INITDB_ROOT_PASSWORD: secret  
	backend:  
		build: ./backend  
			container_name: backend  
		ports:  
			- 80:80  
		volumes:  
			- logs:/app/logs  
			- ./backend:/app  
			- /app/node_modules  
		env_file:  
			- ./env/backend.env  
		depends_on:  
			- mongodb  
	frontend:  
		build: ./frontend  
		container_name: frontend  
		ports:  
			- 3000:3000  
		volumes:  
			- ./frontend/src:/app/src  
		stdin_open: true  
		tty: true  
		depends_on:  
			- backend  
  
volumes:  
	data:  
	logs:  
```  
  
Now that we have the configuration in order, all we gotta do is run this single command.  
  
```shell  
$ docker compose up -d  
```  
  
And to stop all of the containers, there is still just one command. This will remove all containers and images as well.  
  
```shell  
$ docker compose down --remove-orphans  
$ docker image prune -a  
```  
  
This is why Docker Compose is such a powerful tool. We can start and stop our containers quickly while we iron out our configuration and we don’t have to type everything at the CLI. This allows us to focus on more complex implementations and security techniques.  
  
## Advanced Topics  
  
Now that we have proven the usefulness of Docker Compose (and hopefully validated the length of this section) there are a couple more advanced topics we need to cover before we move on. These topics will be used in the project and more may be added as we harden our configuration.  
  
### Using Environment Variables  
  
The Docker Compose file can use environment variables if those variables are defined in a `.env` file within the same directory. We will not store credentials, secrets, or sensitive information in this file; just image versions, common paths, project-specific conventions, and user/group identifiers. All sensitive information will be shared with containers via [Docker Secrets](0.6-Docker-Compose.md#the-secrets-attribute).  
  
We have opted to use this functionality for a few reasons:  
  
- An `.env` file reduces the verboseness of `docker-compose.yml` and even the Dockerfiles. Plus, it helps reduce redundancy for variables that are used in more than one container.  
- Hardcoding paths and common configuration variables gets tedious when you decide to clean up your directory or move files.  
- Keeping all of our environment variables in a single file helps make development easier as you don’t need to switch between the Dockerfiles, Docker Compose, and other configuration files when changes are made to a variable.  
  
As demonstrated in the [env_file](0.6-Docker-Compose.md#the-envfile-attribute) attribute heading, the `.env` uses simple `key=value` notation and can be referenced in the Docker Compose file as follows:  
  
```yml  
services:  
	foo:  
		build:  
			args:  
				- VARIABLE=${key}  
```  
  
Conceptually, we will use environment variables like this:  
  
- One master `.env` file will be used to hold all variables used in the configuration of the project. Another file, `production.env` will be developed at a later date to customize the build for that environment but will effectively mirror the master, only with production ready values and extended security. Considerable modifications will be made to our entire configuration between development, testing, and production environments but we will make this process as smooth as possible keeping those changes in mind from the beginning.  
- Each container will be granted access to only those variables which it uses directly. This means we will not be using the `.env` file directly as this would give containers access to the variables of other containers which may lead to privilege escalation if attacked. Instead will use the [environments](0.6-Docker-Compose.md#the-envfile-attribute) attribute in our Docker Compose and supply the `docker-compose.yml` the variables using the `.env` file.  
- Since our containers will have environment variables defined, their configuration files will be able to use them. Anywhere that a variable can be used, we will grant that service access to do so. This keeps our service-specific configuration files (e.g., `.ini` and `.conf` files) clean and portable in case of routine development changes or environment/scope changes. If we update a variable in the one `.env` file, the changes will be reflected in all the places it is needed without needing to scour each file looking for a line number.  
  
> 🔮 Crystal Ball    
> If you are looking to simply copy and paste an `.env` file from the project github you will not find one. To secure my own implementation and host details, I have instead provided a heavily commented `example.env` file in the root directory of this repository. You can find it [here](../../example.env). As long as you follow along with the tutorial, it should be clear how to flesh out the values.  
  
### Using Multiple Docker Compose Files  
  
There are many instances where our development images and production images need to differ in order to meet the requirements of either environment. For example, in our development images, we may wish to use volumes to provide live access to the contents of a container as well as update our code. In production, this is not necessary and is quite insecure. We may also wish to override certain build elements like excluding a service that is not a part of the production workflow.  
  
Docker enables you to use multiple Docker Compose files by *extending* the master `docker-compose.yml` using additional `.yml` files. You can name these files however you like, however, Docker Compose does automatically recognize an `docker-compose.override.yml` file. Besides this exception, any other `.yml` file must be named during the `docker compose up` command using the `-f` or `--file` flag. Any files used in this way must have their path designated relative to the master `.yml` file.  
  
```shell  
$ docker compose -f docker-compose.yml -f docker-compose.production.yml up -d  
```  
  
By convention, the `docker-compose.yml` will contain the base configuration for our containers and the `docker-compose.override.yml` will contain configuration that can both extend those or define all new ones. The order of precedence for additional Docker Compose files is not super intuitive but they boil down to the following:  
  
- The master `.yml` will be copied over to the added one.  
- If a service is not defined in both files, the master `.yml` will simply merge with the new `.yml` without conflict.  
- If a service is defined in both files, Docker Compose will merge the attribute definitions according to several rules.  
	- Any attributes that require a single-value option (i.e., `image`, `command`,`mem_limit`, etc) will be replaced by the override `.yml` file/s.  
	- If the original services accept multi-value options:  
		- Those of the master will be appended to the top of that service’s attribute definition in the override file. This would give the placement of the override values precedence in case any variables contains the same name for attributes like `environemnts` and `ports`.  
		- In the case of attributes like `volumes` and `devices`, if the destinations are the same, the bind mount of the override file will win out.  
  
> 🪟 See Also    
>  To read more about merge and extend rules, visit the official [Docker Docs](https://docs.docker.com/compose/extends/#adding-and-overriding-configuration) site. There are several examples that help illustrate these principles.  
  
We will be using the following naming convention for our Docker Compose files:  
  
- `docker-compose.yml` will contain our base Docker Compose configuration and is suitable for use in both development and production (though I read that this is an old convention and has been superseded by the file `compose.yml`).  
- `docker-compose.development.yml` will contain configuration specific for the development phase of the project including extending our services by adding `volumes` definitions and the PHPMyAdmin service.  
- `docker-compose.production.yml` will contain narrowed security and no `volumes` or `bind mounts`. Credentials and secrets will also need to be updated or overridden in this file.  
  
## Wrapping Up  
  
That was a lot! And the longer I work on this project, the more I find to try out. The work of a developer is never done because a project should continue to improve and become more secure throughout its entire lifecycle; not just when a breach is made. This follows the [DevSecOps](https://owasp.org/www-project-devsecops-guideline/) culture of development; a set of design principles backed by [OWASP](OWASP Foundation, the Open Source Foundation for Application Security | OWASP Foundation](<https://owasp.org/)).>  
  
This Module may be edited for content in the future as I filter through exactly what is within the scope of the project and determine changes moving forward. This project is fluid and I am still learning more and more everyday. Edits such as that will be documented in the [EDITS](../EDITS.md#) file, though slight tweaks may be overlooked.  
  
> 🪟 See Also    
> Module 1 will discuss more [Design Principles](../1-Dockerizing/0.0-The-Stack.md#design-principles)( such as those used in these advanced topics) that will guide our security and configuration posturing.  
  
Now that we’ve covered all the tools and concepts we will start our project using, it’s finally time to get to it!  
  
---  
  
## References  
  
Docker. (2019, May 8). *Compose file version 3 reference*. Docker Documentation. <https://docs.docker.com/compose/compose-file/>  
  
Docker. (2022, August 12). *Manage sensitive data with Docker secrets*. Docker Documentation. <https://docs.docker.com/engine/swarm/secrets/>  
  
Docker. (2023, July 8). *Share Compose configurations between files and projects*. Docker Documentation. <https://docs.docker.com/compose/extends/#adding-and-overriding-configuration>  
  
Scwarzmüller, M. (2023). Docker & Kubernetes: The Practical Guide [MOOC]. Section 5: Building Multi-Container Applications with Docker. Udemy. <https://www.udemy.com/share/103Ia03@NIeuWLCBpXz9Asqz04rkP-_CNSQIKXErlgRJiOPMlNKtC0p-elHO_4KXZAlK3wo=/>    
‌  
